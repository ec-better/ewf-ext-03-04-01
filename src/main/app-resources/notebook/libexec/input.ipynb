{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##  ewf-ext-03-04-01 - Temperature and Chlorophyll anomalies for coastal areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'ewf-ext-03-04-01 - Temperature and Chlorophyll anomalies for coastal areas'),\n",
    "                ('abstract', 'ewf-ext-03-04-01 - Temperature and Chlorophyll anomalies for coastal areas'),\n",
    "                ('id', 'ewf-ext-03-04-01')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yoi = dict([('id', 'yoi'),\n",
    "            ('value', '2018'),\n",
    "            ('title', 'year of interest'),\n",
    "            ('abstract', 'year of interest')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = dict([('id', 'start_year'),\n",
    "            ('value', '2018'),\n",
    "            ('title', 'start year'),\n",
    "            ('abstract', 'start year')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_year = dict([('id', 'end_year'),\n",
    "            ('value', '2018'),\n",
    "            ('title', 'end_year'),\n",
    "            ('abstract', 'end_year')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_of_interest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON ((0.601779726018505 42.8075056025504,5.06836475455413 42.8075056025504,5.06836475455413 39.2520150325718,0.601779726018505 39.2464595785562,0.601779726018505 42.8075056025504))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = dict([('id', 'areaOfInterest'),\n",
    "                         ('value', 'europe'),\n",
    "                         ('title', 'Area of the region'),\n",
    "                         ('abstract', 'Area of the region of interest')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_variable = dict([('id', 'image_variable'),\n",
    "                         ('value', 'sea_surface_temperature'),\n",
    "                         ('title', 'Image Variable'),\n",
    "                         ('abstract', 'Image Variable of Interest')])\n",
    "\n",
    "#concentration_of_chlorophyll_in_sea_water\n",
    "#chl\n",
    "#sea_surface_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = dict([('id', 'startdate'),\n",
    "                  ('value', '2018-01-01T00:00Z'),\n",
    "                  ('title', 'Start date'),\n",
    "                  ('abstract', 'Start date')])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enddate = dict([('id', 'enddate'),\n",
    "                ('value', '2018-01-10T23:59Z'),\n",
    "                ('title', 'End date'),\n",
    "                ('abstract', 'End date')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue_url = dict([('id', 'catalogue_url'),\n",
    "                      ('value', 'https://catalog.terradue.com/cmems/search'),\n",
    "                      ('title', 'catalogue url for chirps products'),\n",
    "                      ('abstract', 'catalogue url for cmems products')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name = dict([('id', 'product_name'),\n",
    "                      ('value', 'SST_MED_SST_L3S_NRT_OBSERVATIONS_010_012_a'),\n",
    "                      ('title', 'name of products'),\n",
    "                      ('abstract', 'name of products')])\n",
    "\n",
    "#MED_BIO_006_008_PFTC\n",
    "#SST_MED_SST_L3S_NRT_OBSERVATIONS_010_012_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the Sentinel-1 stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "input_references = ('https://catalog.terradue.com/cmems/search?format=atom&uid=20171201_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20171101_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20171001_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20170901_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20170801_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20170701_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20170601_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20170501_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20170401_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20170301_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20170201_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20170101_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20181201_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20181101_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20181001_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20180901_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20180801_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20180701_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20180601_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20180501_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20180401_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20180301_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20180201_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    " 'https://catalog.terradue.com/cmems/search?format=atom&uid=20180101_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10')\n",
    "'''\n",
    "input_references=('https://catalog.terradue.com/cmems/search?format=atom&uid=20180110000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "'https://catalog.terradue.com/cmems/search?format=atom&uid=20180109000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "'https://catalog.terradue.com/cmems/search?format=atom&uid=20180108000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "'https://catalog.terradue.com/cmems/search?format=atom&uid=20180107000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "'https://catalog.terradue.com/cmems/search?format=atom&uid=20180106000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "'https://catalog.terradue.com/cmems/search?format=atom&uid=20180105000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "'https://catalog.terradue.com/cmems/search?format=atom&uid=20180104000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "'https://catalog.terradue.com/cmems/search?format=atom&uid=20180103000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "'https://catalog.terradue.com/cmems/search?format=atom&uid=20180102000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "'https://catalog.terradue.com/cmems/search?format=atom&uid=20180101000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input_identifiers = ('20171201_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20171101_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20171001_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20170901_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20170801_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20170701_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20170601_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20170501_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20170401_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20170301_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20170201_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20170101_m-OGS--PFTC-MedBFM1-MED-b20190402_re-sv04.10',\n",
    "'20181201_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    "'20181101_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    "'20181001_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    "'20180901_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    "'20180801_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    "'20180701_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    "'20180601_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    "'20180501_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    "'20180401_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    "'20180301_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    "'20180201_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10',\n",
    "'20180101_m-OGS--PFTC-MedBFM1-MED-b20191101_re-sv04.10')\n",
    "'''\n",
    "\n",
    "input_identifiers = ('20180101000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "                    '20180102000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "                    '20180103000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "                    '20180104000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "                    '20180105000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "                    '20180106000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "                    '20180107000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "                    '20180108000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "                    '20180109000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0',\n",
    "                    '20180110000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the Sentinel-1 stack catalogue references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace\"\n",
    "#data_path = \"/workspace/data/CMEMS/MEDSEA_REANALYSIS_BIO_006_008\"\n",
    "\n",
    "#data_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'Temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_output_folder = 'Crop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "import datetime\n",
    "\n",
    "import pdb\n",
    "from calendar import monthrange\n",
    "\n",
    "import cioppy\n",
    "ciop = cioppy.Cioppy()\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# remove contents of a given folder\n",
    "# used to clean a temporary folder\n",
    "def mallwhere(mat1, mat2, cond):\n",
    "    mat3=mat1.copy()\n",
    "    mat3[cond] = mat2[cond]\n",
    "    return mat3\n",
    "\n",
    "def mallwhere_value(mat1, value2, cond):\n",
    "    mat3=mat1.copy()\n",
    "    mat3[cond] = value2\n",
    "    return mat3\n",
    "\n",
    "def rm_cfolder(folder):\n",
    "    #folder = '/path/to/folder'\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "\n",
    "def crop_image(input_image, polygon_wkt, output_path, product_type=None):\n",
    "    dataset = None\n",
    "        \n",
    "    if input_image.startswith('ftp://') or input_image.startswith('http'):\n",
    "        try:\n",
    "            dataset = gdal.Open('/vsigzip//vsicurl/%s' % input_image)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    elif '.nc' in input_image:\n",
    "        dataset = gdal.Open('NETCDF:' + input_image + ':' + product_type)\n",
    "\n",
    "    polygon_ogr = ogr.CreateGeometryFromWkt(polygon_wkt)\n",
    "    envelope = polygon_ogr.GetEnvelope()\n",
    "    bounds = [envelope[0], envelope[3], envelope[1], envelope[2]]         \n",
    "\n",
    "    gdal.Translate(output_path, dataset, outputType=gdal.GDT_Int16, projWin=bounds, projWinSRS='EPSG:4326')\n",
    "\n",
    "    dataset = None\n",
    "\n",
    "\n",
    "    \n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, mask=None, output_projection=None, output_geotransform=None, no_data_value=None):\n",
    "    \n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    \n",
    "    \n",
    "    if mask is not None and mask is not 0:\n",
    "        # TODO: check if output folder exists\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "        if no_data_value is not None:\n",
    "            output_matrix[mask > 0] = no_data_value\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "    \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    \n",
    "    if filepath is None:\n",
    "        print  \"filepath\"\n",
    "    if output is None:\n",
    "        print  \"output\"\n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "\n",
    "    \n",
    "def calc_max_matrix(mat1, mat2, no_data_value=None):\n",
    "    \n",
    "    if no_data_value is not None:\n",
    "        if not isinstance(mat1, int):\n",
    "            mat1[(mat1 == no_data_value)] = 0\n",
    "        if not isinstance(mat2, int):\n",
    "            mat2[(mat2 == no_data_value)] = 0\n",
    "    \n",
    "    mallwhere(mat2, mat1, mat1>mat2)\n",
    "    #return np.where(mat1 > mat2, mat1, mat2)\n",
    "    return mat3\n",
    "\n",
    "def matrix_sum(mat1, mat2, no_data_value=None):\n",
    "    if no_data_value is not None:\n",
    "        if not isinstance(mat1, int):\n",
    "            mat1[(mat1 == no_data_value)] = 0\n",
    "        if not isinstance(mat2, int):\n",
    "            mat2[(mat2 == no_data_value)] = 0\n",
    "            \n",
    "            \n",
    "    msum = mat1 + mat2\n",
    "    return msum\n",
    "\n",
    "def matrix_sum_for_avg(mat1, mat2, mat_n_vals, no_data_value):\n",
    "\n",
    "    no_data_value_alt = -32768\n",
    "    \n",
    "    mat2_0and1s = np.zeros(mat2.shape)\n",
    "    \n",
    "    mat2_0and1s[mat2 != no_data_value] = 1\n",
    "    \n",
    "    \n",
    "    mat_n_vals = mat2_0and1s;\n",
    "    \n",
    "    \n",
    "    #msum = mat1\n",
    "    \n",
    "    msum = np.copy(mat1)\n",
    "    \n",
    "    msum[mat2 != no_data_value] = mat1[mat2 != no_data_value] + mat2[mat2 != no_data_value]\n",
    "    \n",
    "    #msum = np.where(np.logical_and(mat1 == no_data_value_alt, mat2 != no_data_value), mat2, msum)\n",
    "    \n",
    "    msum = mallwhere(msum, mat2,np.logical_and(mat1 == no_data_value_alt, mat2 != no_data_value))\n",
    "\n",
    "    msum[np.logical_and(mat1 == no_data_value_alt, mat2 == no_data_value) ] = no_data_value\n",
    "\n",
    "    \n",
    "    \n",
    "    #msum = mat1 + mat2\n",
    "\n",
    "    return msum, mat_n_vals\n",
    "\n",
    "\n",
    "def calc_average(matrix_list, n_matrix, no_data_value=None):\n",
    "\n",
    "    no_data_value_alt = -32768\n",
    "    \n",
    "    if not isinstance(matrix_list, list):\n",
    "        return 0\n",
    "    \n",
    "    result = np.copy(matrix_list[0])\n",
    "    \n",
    "    #result = np.where(result == no_data_value, no_data_value_alt, result)\n",
    "    \n",
    "    result = mallwhere_value(result, no_data_value_alt, result == no_data_value)\n",
    "    \n",
    "    mat_n_vals = np.zeros(result.shape)\n",
    "    mat_n_vals[result != no_data_value_alt] = 1\n",
    "    \n",
    "    for i in range(1, len(matrix_list)):\n",
    "     \n",
    "        result, mat_n_vals_of_sum = matrix_sum_for_avg(result, matrix_list[i], mat_n_vals, no_data_value)\n",
    "        \n",
    "        #result = np.copy(result_temp)\n",
    "        \n",
    "        mat_n_vals = mat_n_vals + mat_n_vals_of_sum\n",
    "    \n",
    "\n",
    "    # to avoid division by 0!!\n",
    "    mat_n_vals[mat_n_vals == 0] = no_data_value_alt\n",
    "\n",
    "    result = np.divide(result, mat_n_vals)\n",
    "    \n",
    "    # set as no data value pixels that are no data values in all time series\n",
    "    result[mat_n_vals == no_data_value_alt] = no_data_value\n",
    "    \n",
    "    return result\n",
    "\n",
    "def matrix_sum_for_sigma(mat1, mat2, mat_n_vals, avgmat, no_data_value):\n",
    "\n",
    "    no_data_value_alt = -32768\n",
    "    \n",
    "    mat2_0and1s = np.zeros(mat2.shape)\n",
    "    \n",
    "    mat2_0and1s[mat2 != no_data_value] = 1\n",
    "    \n",
    "    \n",
    "    mat_n_vals = mat2_0and1s;\n",
    "    \n",
    "    \n",
    "    #msum = mat1\n",
    "    \n",
    "    msum = np.copy(mat1)\n",
    "    #(matrix_list[0] - avgmat)**2\n",
    "    msum[mat2 != no_data_value] = mat1[mat2 != no_data_value] + (mat2[mat2 != no_data_value] - avgmat[mat2 != no_data_value])**2\n",
    "    \n",
    "    #msum = np.where(np.logical_and(mat1 == no_data_value_alt, mat2 != no_data_value), (mat2 - avgmat)**2, msum)\n",
    "    msum = mallwhere(msum, (mat2 - avgmat)**2, np.logical_and(mat1 == no_data_value_alt, mat2 != no_data_value))\n",
    "\n",
    "    msum[np.logical_and(mat1 == no_data_value_alt, mat2 == no_data_value) ] = no_data_value\n",
    "\n",
    "    \n",
    "    \n",
    "    #msum = mat1 + mat2\n",
    "\n",
    "    return msum, mat_n_vals\n",
    "\n",
    "\n",
    "def calc_standarddeviation(matrix_list, n_matrix, avgmat, no_data_value=None):\n",
    "\n",
    "    no_data_value_alt = -32768\n",
    "    \n",
    "    if not isinstance(matrix_list, list):\n",
    "        return 0\n",
    "    \n",
    "    result = (matrix_list[0] - avgmat)**2\n",
    "    \n",
    "    \n",
    "    #result = np.where(matrix_list[0] == no_data_value, no_data_value_alt, result)\n",
    "    result = mallwhere_value(result, no_data_value_alt, matrix_list[0] == no_data_value)\n",
    "    \n",
    "    mat_n_vals = np.zeros(result.shape)\n",
    "    mat_n_vals[result != no_data_value_alt] = 1\n",
    "    \n",
    "    for i in range(1, len(matrix_list)):\n",
    "     \n",
    "        result, mat_n_vals_of_sum = matrix_sum_for_sigma(result, matrix_list[i], mat_n_vals, avgmat, no_data_value)\n",
    "        \n",
    "        #result = np.copy(result_temp)\n",
    "        \n",
    "        mat_n_vals = mat_n_vals + mat_n_vals_of_sum\n",
    "    \n",
    "\n",
    "    # to avoid division by 0!!\n",
    "    mat_n_vals[mat_n_vals == 0] = no_data_value_alt\n",
    "\n",
    "    result = np.sqrt(np.divide(result, mat_n_vals))\n",
    "    \n",
    "    # set as no data value pixels that are no data values in all time series\n",
    "    result[mat_n_vals == no_data_value_alt] = no_data_value\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_matrix_list(image_list, product_type):\n",
    "    projection = None\n",
    "    geo_transform = None\n",
    "    no_data = None\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        print img\n",
    "        print product_type\n",
    "        dataset = gdal.Open('NETCDF:' + img + ':' + product_type)\n",
    "        print dataset\n",
    "        projection = dataset.GetProjection()\n",
    "        print projection\n",
    "        geo_transform = dataset.GetGeoTransform()\n",
    "        no_data = dataset.GetRasterBand(1).GetNoDataValue()\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list, projection, geo_transform, no_data\n",
    "\n",
    "def calculate_anomaly(averagesigma, doy, no_value):\n",
    "    \n",
    "    above = doy > averagesigma\n",
    "    below = doy < averagesigma\n",
    "    \n",
    "    above[averagesigma == no_value] = 0\n",
    "    below[averagesigma == no_value] = 0\n",
    "    \n",
    "    return above*1, below*1\n",
    "    \n",
    "\n",
    "def write_outputs(product_name, first_date, last_date, averages, standard_deviation, image_format, projection, geo_transform, no_data_value, producttype):\n",
    "    \n",
    "    filenames = []\n",
    "    areaofinterest = area_of_interest['value']\n",
    "    filenames.append(product_name + '_averages_' + areaofinterest + '_' + first_date + '_' + last_date + '.tif')\n",
    "    filenames.append(product_name + '_standarddeviation_' + areaofinterest + '_'+ first_date + '_' + last_date + '.tif')\n",
    "\n",
    "    write_output_image(filenames[0], averages, image_format, producttype, None, projection, geo_transform, no_data_value)\n",
    "    write_output_image(filenames[1], standard_deviation, image_format, producttype, None, projection, geo_transform, no_data_value)\n",
    "    \n",
    "    return filenames\n",
    "\n",
    "def isleap(year):\n",
    "    \"\"\"Return True for leap years, False for non-leap years.\"\"\"\n",
    "    return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    first_date = get_formatted_date(first_date)\n",
    "    last_date = get_formatted_date(last_date)\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (region_of_interest))\n",
    "        \n",
    "def get_formatted_date(date_obj):\n",
    "    date = datetime.datetime.strftime(date_obj, '%Y-%m-%dT00:00:00Z')\n",
    "    return date\n",
    "\n",
    "def get_input_metadata (input_refs):\n",
    "    \n",
    "    # for each product get metadata\n",
    "    Result_Prod = []\n",
    "    for index,product_ref in enumerate(input_refs):  \n",
    "        # since the search is by identifier \n",
    "        Result_Prod.append(ciop.search(end_point = product_ref,params =[],output_fields='self,identifier,startdate,enclosure,startdate,enddate,wkt,title')[0] )    \n",
    "\n",
    "    input_metadata = pd.DataFrame.from_dict(Result_Prod)\n",
    "    print input_metadata\n",
    "    input_metadata['startdate'] = pd.to_datetime(input_metadata['startdate'])\n",
    "    input_metadata['enddate'] = pd.to_datetime(input_metadata['enddate'])\n",
    "    \n",
    "    \n",
    "    return input_metadata\n",
    "   \n",
    "        \n",
    "def enclosurelist (listl):\n",
    "    newlist = []\n",
    "    for label, content in listl.items():\n",
    "        found = False\n",
    "        if label == 'enclosure':\n",
    "            found = True\n",
    "            for enclosure in content:\n",
    "                newlist.append(enclosure)\n",
    "        if found:\n",
    "            return newlist\n",
    "\n",
    "def identifierlist (listl):\n",
    "    newlist = []\n",
    "    for label, content in listl.items():\n",
    "        found = False\n",
    "        if label == 'identifier':\n",
    "            found = True\n",
    "            for identifier in content:\n",
    "                newlist.append(identifier)\n",
    "        if found:\n",
    "            return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load metadata from catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reporter:status:2021-01-27T18:13:17.937366 [INFO   ] [user process] Loading metadata from catalog\n",
      "2021-01-27T18:13:17.937366 [INFO   ] [user process] Loading metadata from catalog\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           enclosure  \\\n",
      "0  https://store.terradue.com/download/cmems/file...   \n",
      "1  https://store.terradue.com/download/cmems/file...   \n",
      "2  https://store.terradue.com/download/cmems/file...   \n",
      "3  https://store.terradue.com/download/cmems/file...   \n",
      "4  https://store.terradue.com/download/cmems/file...   \n",
      "5  https://store.terradue.com/download/cmems/file...   \n",
      "6  https://store.terradue.com/download/cmems/file...   \n",
      "7  https://store.terradue.com/download/cmems/file...   \n",
      "8  https://store.terradue.com/download/cmems/file...   \n",
      "9  https://store.terradue.com/download/cmems/file...   \n",
      "\n",
      "                        enddate  \\\n",
      "0  2018-01-10T23:59:59.0000000Z   \n",
      "1  2018-01-09T23:59:59.0000000Z   \n",
      "2  2018-01-08T23:59:59.0000000Z   \n",
      "3  2018-01-07T23:59:59.0000000Z   \n",
      "4  2018-01-06T23:59:59.0000000Z   \n",
      "5  2018-01-05T23:59:59.0000000Z   \n",
      "6  2018-01-04T23:59:59.0000000Z   \n",
      "7  2018-01-03T23:59:59.0000000Z   \n",
      "8  2018-01-02T23:59:59.0000000Z   \n",
      "9  2018-01-01T23:59:59.0000000Z   \n",
      "\n",
      "                                          identifier  \\\n",
      "0  20180110000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
      "1  20180109000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
      "2  20180108000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
      "3  20180107000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
      "4  20180106000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
      "5  20180105000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
      "6  20180104000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
      "7  20180103000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
      "8  20180102000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
      "9  20180101000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
      "\n",
      "                                                self  \\\n",
      "0  https://catalog.terradue.com/cmems/search?form...   \n",
      "1  https://catalog.terradue.com/cmems/search?form...   \n",
      "2  https://catalog.terradue.com/cmems/search?form...   \n",
      "3  https://catalog.terradue.com/cmems/search?form...   \n",
      "4  https://catalog.terradue.com/cmems/search?form...   \n",
      "5  https://catalog.terradue.com/cmems/search?form...   \n",
      "6  https://catalog.terradue.com/cmems/search?form...   \n",
      "7  https://catalog.terradue.com/cmems/search?form...   \n",
      "8  https://catalog.terradue.com/cmems/search?form...   \n",
      "9  https://catalog.terradue.com/cmems/search?form...   \n",
      "\n",
      "                      startdate              title  \\\n",
      "0  2018-01-10T00:00:00.0000000Z  Mediterranean SST   \n",
      "1  2018-01-09T00:00:00.0000000Z  Mediterranean SST   \n",
      "2  2018-01-08T00:00:00.0000000Z  Mediterranean SST   \n",
      "3  2018-01-07T00:00:00.0000000Z  Mediterranean SST   \n",
      "4  2018-01-06T00:00:00.0000000Z  Mediterranean SST   \n",
      "5  2018-01-05T00:00:00.0000000Z  Mediterranean SST   \n",
      "6  2018-01-04T00:00:00.0000000Z  Mediterranean SST   \n",
      "7  2018-01-03T00:00:00.0000000Z  Mediterranean SST   \n",
      "8  2018-01-02T00:00:00.0000000Z  Mediterranean SST   \n",
      "9  2018-01-01T00:00:00.0000000Z  Mediterranean SST   \n",
      "\n",
      "                                                 wkt  \n",
      "0   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
      "1   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
      "2   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
      "3   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
      "4   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
      "5   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
      "6   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
      "7   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
      "8   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
      "9   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enclosure</th>\n",
       "      <th>enddate</th>\n",
       "      <th>identifier</th>\n",
       "      <th>self</th>\n",
       "      <th>startdate</th>\n",
       "      <th>title</th>\n",
       "      <th>wkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://store.terradue.com/download/cmems/file...</td>\n",
       "      <td>2018-01-10 23:59:59</td>\n",
       "      <td>20180110000000-GOS-L3S_GHRSST-SSTsubskin-night...</td>\n",
       "      <td>https://catalog.terradue.com/cmems/search?form...</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Mediterranean SST</td>\n",
       "      <td>L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://store.terradue.com/download/cmems/file...</td>\n",
       "      <td>2018-01-09 23:59:59</td>\n",
       "      <td>20180109000000-GOS-L3S_GHRSST-SSTsubskin-night...</td>\n",
       "      <td>https://catalog.terradue.com/cmems/search?form...</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>Mediterranean SST</td>\n",
       "      <td>L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://store.terradue.com/download/cmems/file...</td>\n",
       "      <td>2018-01-08 23:59:59</td>\n",
       "      <td>20180108000000-GOS-L3S_GHRSST-SSTsubskin-night...</td>\n",
       "      <td>https://catalog.terradue.com/cmems/search?form...</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>Mediterranean SST</td>\n",
       "      <td>L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://store.terradue.com/download/cmems/file...</td>\n",
       "      <td>2018-01-07 23:59:59</td>\n",
       "      <td>20180107000000-GOS-L3S_GHRSST-SSTsubskin-night...</td>\n",
       "      <td>https://catalog.terradue.com/cmems/search?form...</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>Mediterranean SST</td>\n",
       "      <td>L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://store.terradue.com/download/cmems/file...</td>\n",
       "      <td>2018-01-06 23:59:59</td>\n",
       "      <td>20180106000000-GOS-L3S_GHRSST-SSTsubskin-night...</td>\n",
       "      <td>https://catalog.terradue.com/cmems/search?form...</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>Mediterranean SST</td>\n",
       "      <td>L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://store.terradue.com/download/cmems/file...</td>\n",
       "      <td>2018-01-05 23:59:59</td>\n",
       "      <td>20180105000000-GOS-L3S_GHRSST-SSTsubskin-night...</td>\n",
       "      <td>https://catalog.terradue.com/cmems/search?form...</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>Mediterranean SST</td>\n",
       "      <td>L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://store.terradue.com/download/cmems/file...</td>\n",
       "      <td>2018-01-04 23:59:59</td>\n",
       "      <td>20180104000000-GOS-L3S_GHRSST-SSTsubskin-night...</td>\n",
       "      <td>https://catalog.terradue.com/cmems/search?form...</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>Mediterranean SST</td>\n",
       "      <td>L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://store.terradue.com/download/cmems/file...</td>\n",
       "      <td>2018-01-03 23:59:59</td>\n",
       "      <td>20180103000000-GOS-L3S_GHRSST-SSTsubskin-night...</td>\n",
       "      <td>https://catalog.terradue.com/cmems/search?form...</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Mediterranean SST</td>\n",
       "      <td>L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://store.terradue.com/download/cmems/file...</td>\n",
       "      <td>2018-01-02 23:59:59</td>\n",
       "      <td>20180102000000-GOS-L3S_GHRSST-SSTsubskin-night...</td>\n",
       "      <td>https://catalog.terradue.com/cmems/search?form...</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Mediterranean SST</td>\n",
       "      <td>L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://store.terradue.com/download/cmems/file...</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>20180101000000-GOS-L3S_GHRSST-SSTsubskin-night...</td>\n",
       "      <td>https://catalog.terradue.com/cmems/search?form...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Mediterranean SST</td>\n",
       "      <td>L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enclosure             enddate  \\\n",
       "0  https://store.terradue.com/download/cmems/file... 2018-01-10 23:59:59   \n",
       "1  https://store.terradue.com/download/cmems/file... 2018-01-09 23:59:59   \n",
       "2  https://store.terradue.com/download/cmems/file... 2018-01-08 23:59:59   \n",
       "3  https://store.terradue.com/download/cmems/file... 2018-01-07 23:59:59   \n",
       "4  https://store.terradue.com/download/cmems/file... 2018-01-06 23:59:59   \n",
       "5  https://store.terradue.com/download/cmems/file... 2018-01-05 23:59:59   \n",
       "6  https://store.terradue.com/download/cmems/file... 2018-01-04 23:59:59   \n",
       "7  https://store.terradue.com/download/cmems/file... 2018-01-03 23:59:59   \n",
       "8  https://store.terradue.com/download/cmems/file... 2018-01-02 23:59:59   \n",
       "9  https://store.terradue.com/download/cmems/file... 2018-01-01 23:59:59   \n",
       "\n",
       "                                          identifier  \\\n",
       "0  20180110000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
       "1  20180109000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
       "2  20180108000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
       "3  20180107000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
       "4  20180106000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
       "5  20180105000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
       "6  20180104000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
       "7  20180103000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
       "8  20180102000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
       "9  20180101000000-GOS-L3S_GHRSST-SSTsubskin-night...   \n",
       "\n",
       "                                                self  startdate  \\\n",
       "0  https://catalog.terradue.com/cmems/search?form... 2018-01-10   \n",
       "1  https://catalog.terradue.com/cmems/search?form... 2018-01-09   \n",
       "2  https://catalog.terradue.com/cmems/search?form... 2018-01-08   \n",
       "3  https://catalog.terradue.com/cmems/search?form... 2018-01-07   \n",
       "4  https://catalog.terradue.com/cmems/search?form... 2018-01-06   \n",
       "5  https://catalog.terradue.com/cmems/search?form... 2018-01-05   \n",
       "6  https://catalog.terradue.com/cmems/search?form... 2018-01-04   \n",
       "7  https://catalog.terradue.com/cmems/search?form... 2018-01-03   \n",
       "8  https://catalog.terradue.com/cmems/search?form... 2018-01-02   \n",
       "9  https://catalog.terradue.com/cmems/search?form... 2018-01-01   \n",
       "\n",
       "               title                                                wkt  \n",
       "0  Mediterranean SST   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
       "1  Mediterranean SST   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
       "2  Mediterranean SST   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
       "3  Mediterranean SST   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
       "4  Mediterranean SST   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
       "5  Mediterranean SST   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
       "6  Mediterranean SST   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
       "7  Mediterranean SST   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
       "8  Mediterranean SST   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  \n",
       "9  Mediterranean SST   L3S, 1/16deg daily (SST_MED_SST_L3S_NRT_OBSER...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = 'Loading metadata from catalog' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "prods = get_input_metadata (input_references)\n",
    "prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_identifiers = enclosurelist(prods)\n",
    "input_identifiers = identifierlist(prods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2018', '2018', '2018')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoi['value'], start_year['value'], end_year['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/https://store.terradue.com/download/cmems/files/v1/20180101000000-GOS-L3S_GHRSST-SSTsubskin-night_SST_HR_NRT-MED-v02.0-fv01.0.nc\n",
      "sea_surface_temperature\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'GetProjection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3847172187a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_years\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mmat_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeo_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matrix_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_variable_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mstandarddeviations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_standarddeviation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-093cc0d7cc89>\u001b[0m in \u001b[0;36mget_matrix_list\u001b[0;34m(image_list, product_type)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NETCDF:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mproduct_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mprojection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetProjection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mgeo_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetGeoTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'GetProjection'"
     ]
    }
   ],
   "source": [
    "aoi = region_of_interest['value']\n",
    "yearofinterest = int(yoi['value'])\n",
    "start_year_int = int(start_year['value'])\n",
    "end_year_int = int(end_year['value'])\n",
    "anomaly_year_index = yearofinterest - start_year_int\n",
    "image_variable_value = image_variable['value']\n",
    "areaofinterest = area_of_interest['value']\n",
    "\n",
    "#os.path.join(temp_folder, 'crop_' + chirp_product)\n",
    "image_variable_value_name = image_variable_value.replace(\"_\", \"\")\n",
    "\n",
    "product_path_name = (output_folder,image_variable_value_name)\n",
    "#product_path_name = output_folder + '/' + image_variable_value_name\n",
    "identifiers = []\n",
    "for identifier in input_identifiers:\n",
    "    identifier = identifier + '.nc'\n",
    "    identifiers.append(identifier)\n",
    "\n",
    "#first_date = os.path.splitext(input_identifiers[0])[0].split('-')[0]\n",
    "#last_date = os.path.splitext(input_identifiers[-1])[0].split('-')[0]\n",
    "\n",
    "#input_identifiers.sort()\n",
    "\n",
    "if identifiers[0].find(\"SST_HR\") >=0:     \n",
    "\n",
    "    doy = 0\n",
    "    \n",
    "    product_path_name = os.path.join(output_folder,image_variable_value_name)\n",
    "    #product_path_name = output_folder + '/' + image_variable_value_name\n",
    "    below = None\n",
    "    above = None\n",
    "    mask_alltime_novalues = None\n",
    "    average = None\n",
    "    projection = None\n",
    "    geo_transform = None\n",
    "    no_data = None\n",
    "    for month in range(1,13):\n",
    "        getout = False\n",
    "        for day in range(1, monthrange(yearofinterest, month)[1]+1):\n",
    "            doy+=1\n",
    "            file_list = []\n",
    "            month_and_day = str(month).zfill(2)  + str(day).zfill(2)\n",
    "            for year in range(start_year_int, end_year_int+1):\n",
    "                date = str(year) + month_and_day + \"000000\"\n",
    "                matching = [s for s in identifiers if date in s]\n",
    "                if len(matching) == 1:\n",
    "                    file = matching[0]\n",
    "                    file_list.append(file)\n",
    "                else:\n",
    "                    print \"file not found on input_identifier => \" + date\n",
    "                    getout = True\n",
    "                    break\n",
    "            if getout == True:\n",
    "                getout = False\n",
    "                break #continue to try the next day, break next month\n",
    "            first_year = file_list[0].split('-')[0][:4]\n",
    "            last_year = file_list[-1].split('-')[0][:4]\n",
    "            first_date = first_year + str(doy).zfill(3)\n",
    "            last_date = last_year + str(doy).zfill(3)\n",
    "            file_list[:] = [os.path.join(data_path, filename) for filename in file_list]\n",
    "            #file_list[:] = [data_path + '/' + filename for filename in file_list]\n",
    "            n_years = end_year_int - start_year_int + 1\n",
    "            \n",
    "            if n_years == len(file_list):\n",
    "                mat_list, projection, geo_transform, no_data = get_matrix_list(file_list, image_variable_value)\n",
    "                average = calc_average(mat_list, len(file_list), no_data)\n",
    "                standarddeviations = calc_standarddeviation(mat_list, len(file_list), average, no_data)\n",
    "                averagesigma = matrix_sum(average, standarddeviations)\n",
    "                #averagesigma[average == no_data] = no_data\n",
    "                above_mat, below_mat = calculate_anomaly(averagesigma, mat_list[anomaly_year_index], no_data)\n",
    "                if (above is None) or (below is None) or (mask_alltime_novalues is None):\n",
    "                    \n",
    "                    above = np.zeros(above_mat.shape)\n",
    "                    below = np.zeros(below_mat.shape)\n",
    "                    \n",
    "                    mask_alltime_novalues = (below == 0)\n",
    "                    \n",
    "                above += above_mat\n",
    "                below += below_mat\n",
    "                \n",
    "                mask_alltime_novalues = np.logical_and(mask_alltime_novalues, (average == no_data))\n",
    "                '''\n",
    "                for i, file in enumerate(file_list):\n",
    "                    cropped_file = os.path.join(cropped_output_folder,file.split('/')[-1])\n",
    "                    #cropped_file = cropped_output_folder + '/'+ file.split('/')[-1]\n",
    "                    crop_image(file, aoi, cropped_file, image_variable_value)\n",
    "                    file_list[i] = cropped_file + '.tif'\n",
    "                '''\n",
    "                files = write_outputs(product_path_name, first_date, last_date, average, standarddeviations, 'GTiff', projection, geo_transform, no_data, gdal.GDT_Int16)\n",
    "\n",
    "                for output_name in files:\n",
    "                    firstdate_obj = datetime.datetime.strptime(first_date, \"%Y%j\").date()\n",
    "                    lastdate_obj = datetime.datetime.strptime(last_date, \"%Y%j\").date()\n",
    "                    write_properties_file(output_name, firstdate_obj, lastdate_obj, region_of_interest['value'])\n",
    "            else:\n",
    "                print \"error\" + str(len(file_list))\n",
    "    #    if getout == True:\n",
    "    #        break\n",
    "    \n",
    "\n",
    "    lastdate_obj_str = lastdate_obj.strftime(\"%Y-%m-%d\")\n",
    "    lastdate_obj_date = datetime.datetime.strptime(lastdate_obj_str, \"%Y-%m-%d\")\n",
    "    last_month = lastdate_obj_date.month\n",
    "    last_day = lastdate_obj_date.day\n",
    "    last_date =  datetime.datetime(int(yoi['value']), last_month, last_day).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    above[mask_alltime_novalues] = no_data\n",
    "    below[mask_alltime_novalues] = no_data\n",
    "    file = write_output_image(product_path_name + '_above_' + areaofinterest + '_' + first_year + '_' + last_year + '_' + str(yearofinterest) + '.tif', above, 'GTiff', gdal.GDT_Int16, None, projection, geo_transform, no_data)\n",
    "    firstdate_obj = datetime.datetime.strptime(first_year, \"%Y\").date()\n",
    "    lastdate_obj = datetime.datetime.strptime(last_date, \"%Y-%m-%d\").date()\n",
    "    print lastdate_obj\n",
    "    write_properties_file(file, firstdate_obj, lastdate_obj, region_of_interest['value'])\n",
    "    file = write_output_image(product_path_name + '_below_' + areaofinterest + '_' + first_year + '_' + last_year + '_' + str(yearofinterest) + '.tif', below, 'GTiff', gdal.GDT_Int16, None, projection, geo_transform, no_data)\n",
    "    write_properties_file(file, firstdate_obj, lastdate_obj, region_of_interest['value'])\n",
    "    \n",
    "else:\n",
    "    product_path_name = os.path.join(output_folder,image_variable_value_name)\n",
    "    #product_path_name = output_folder + '/' + image_variable_value_name\n",
    "    below = None\n",
    "    above = None\n",
    "    mask_alltime_novalues = None\n",
    "    average = None\n",
    "    projection = None\n",
    "    geo_transform = None\n",
    "    no_data = None\n",
    "    for month in range(1,13):\n",
    "        file_list = []\n",
    "        getout = False\n",
    "        for year in range(start_year_int, end_year_int+1):\n",
    "            date = str(year) + str(month).zfill(2) + '01'\n",
    "            matching = [s for s in identifiers if date in s]\n",
    "            print matching\n",
    "            if len(matching) == 1:\n",
    "                file = matching[0]\n",
    "                file_list.append(file)\n",
    "            else:\n",
    "                print \"file not found on input_identifier => \" + date\n",
    "                getout = True\n",
    "                break\n",
    "        if getout == True:\n",
    "            getout = False\n",
    "            break #continue to try the next day, break next month\n",
    "        first_year = file_list[0].split('-')[0][:4]\n",
    "        last_year = file_list[-1].split('-')[0][:4]\n",
    "        first_date = first_year + str(month).zfill(2)\n",
    "        last_date = last_year + str(month).zfill(2)\n",
    "        file_list[:] = [os.path.join(data_path, filename) for filename in file_list]\n",
    "        #file_list[:] = [os.path.join(data_path,'/', (filename for filename in file_list))]\n",
    "        #file_list[:] = [data_path + '/' + filename for filename in file_list]\n",
    "        n_years = end_year_int - start_year_int + 1\n",
    "        \n",
    "        #meter aqui\n",
    "        \n",
    "        if n_years == len(file_list):\n",
    "            mat_list, projection, geo_transform, no_data = get_matrix_list(file_list, image_variable_value)\n",
    "            average = calc_average(mat_list, len(file_list), no_data)\n",
    "            standarddeviations = calc_standarddeviation(mat_list, len(file_list), average, no_data)\n",
    "            averagesigma = matrix_sum(average, standarddeviations)\n",
    "            #averagesigma[average == no_data] = no_data\n",
    "            above_mat, below_mat = calculate_anomaly(averagesigma, mat_list[anomaly_year_index], no_data)\n",
    "            if (above is None) or (below is None) or (mask_alltime_novalues is None):\n",
    "                \n",
    "                above = np.zeros(above_mat.shape)\n",
    "                below = np.zeros(below_mat.shape)\n",
    "                \n",
    "                mask_alltime_novalues = (below == 0)\n",
    "                \n",
    "            above += above_mat\n",
    "            below += below_mat\n",
    "            \n",
    "            mask_alltime_novalues = np.logical_and(mask_alltime_novalues, (average == no_data))\n",
    "            '''\n",
    "            for i, file in enumerate(file_list):\n",
    "                    cropped_file = os.path.join(cropped_output_folder,file.split('/')[-1])\n",
    "                    #cropped_file = cropped_output_folder + '/'+ file.split('/')[-1]\n",
    "                    crop_image(file, aoi, cropped_file, image_variable_value)\n",
    "                    file_list[i] = cropped_file + '.tif'\n",
    "            '''\n",
    "            files = write_outputs(product_path_name, first_date, last_date, average, standarddeviations, 'GTiff', projection, geo_transform, no_data, gdal.GDT_Float32)\n",
    "            for output_name in files:\n",
    "                firstdate_obj = datetime.datetime.strptime(first_date, \"%Y%m\").date()\n",
    "                lastdate_obj = datetime.datetime.strptime(last_date, \"%Y%m\").date()\n",
    "                write_properties_file(output_name, firstdate_obj, lastdate_obj, region_of_interest['value'])\n",
    "        else:\n",
    "            print \"error\" + str(len(file_list))\n",
    "    #    if getout == True:\n",
    "    #        break\n",
    "    \n",
    "    lastdate_obj_str = lastdate_obj.strftime(\"%Y-%m-%d\")\n",
    "    lastdate_obj_date = datetime.datetime.strptime(lastdate_obj_str, \"%Y-%m-%d\")\n",
    "    last_month = lastdate_obj_date.month\n",
    "    last_day = 31\n",
    "    last_date =  datetime.datetime(int(yoi['value']), last_month, last_day).strftime(\"%Y-%m-%d\")\n",
    "    above[mask_alltime_novalues] = no_data\n",
    "    below[mask_alltime_novalues] = no_data\n",
    "    file = write_output_image(product_path_name + '_above_' + areaofinterest + '_' + first_year + '_' + last_year + '_' + str(yearofinterest) + '.tif', above, 'GTiff', gdal.GDT_Float32, None, projection, geo_transform, no_data)\n",
    "    firstdate_obj = datetime.datetime.strptime(first_year, \"%Y\").date()\n",
    "    lastdate_obj = datetime.datetime.strptime(last_date, \"%Y-%m-%d\").date()\n",
    "    write_properties_file(file, firstdate_obj, lastdate_obj, region_of_interest['value'])\n",
    "    file = write_output_image(product_path_name + '_below_' + areaofinterest + '_' + first_year + '_' + last_year + '_' + str(yearofinterest) + '.tif', below, 'GTiff', gdal.GDT_Float32, None, projection, geo_transform, no_data)\n",
    "    write_properties_file(file, firstdate_obj, lastdate_obj, region_of_interest['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(temp_folder)\n",
    "    shutil.rmtree(cropped_output_folder)\n",
    "except OSError as e:\n",
    "    print(\"Error: %s : %s\" % (temp_folder, e.strerror))\n",
    "    print(\"Error: %s : %s\" % (cropped_output_folder, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
